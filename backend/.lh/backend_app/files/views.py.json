{
    "sourceFile": "backend_app/files/views.py",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 2,
            "patches": [
                {
                    "date": 1752323151362,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1752323164437,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -641,11 +641,11 @@\n             print(saved_model.encoder_file)\r\n             print(saved_model.scaler_file)\r\n             print(saved_model.target_encoder)\r\n             \r\n-            # Create filename using model name (sanitized) and ID\r\n+            # Create filename using model name\r\n             from django.utils.text import slugify\r\n-            filename = f\"{slugify(saved_model.name)}_{pk}.zip\"  # slugify handles special chars\r\n+            filename = f\"{slugify(saved_model.name)}_{pk}.zip\" \r\n             \r\n             # Create in-memory zip\r\n             zip_buffer = io.BytesIO()\r\n             with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:\r\n"
                },
                {
                    "date": 1752323210623,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -391,9 +391,9 @@\n                     {'error': f'Error saving scaler: {str(e)}'},\r\n                     status=status.HTTP_500_INTERNAL_SERVER_ERROR\r\n                 )\r\n             \r\n-        accuracy_val = 0.0  # âœ… Initialize with default\r\n+        accuracy_val = 0.0  # Initialize with default\r\n             # print('Config accuracy:',config.get('accuracy'))\r\n             # accuracy = config.get('accuracy')\r\n         print('Accuracy:',accuracy)\r\n         if config.get('problem_type') == 'regression':\r\n@@ -475,9 +475,9 @@\n     \r\n \r\n     def get(self, request):\r\n         try:\r\n-            # Prefetch related data to optimize queries\r\n+            \r\n             models = SavedModel.objects.filter(\r\n                 user=request.user, \r\n                 is_active=True\r\n             ).select_related(\r\n"
                }
            ],
            "date": 1752323151362,
            "name": "Commit-0",
            "content": "from rest_framework import status\r\nfrom rest_framework.views import APIView\r\nfrom rest_framework.decorators import api_view, permission_classes\r\nfrom rest_framework.response import Response\r\nfrom rest_framework.permissions import IsAuthenticated\r\nfrom django.core.files.storage import default_storage\r\n\r\nfrom django.core.cache import cache\r\nfrom django.http import HttpResponse\r\nfrom django.conf import settings\r\nfrom django.core.files.base import ContentFile\r\nimport uuid\r\n\r\nfrom backend_app.models import UploadedDataset, ModelConfig, SavedModel\r\nfrom backend_app.files.serializers import UploadFileSerializer, ModelConfigSerializer, SaveModelSerializer, PredictionSerializer, DatasetPreviewSerializer\r\nfrom backend_app.files.utils import read_file, preprocess_and_train, load_model_and_predict\r\nfrom backend_app.files.permissions import IsCreatedUser\r\n\r\nimport pandas as pd\r\nimport joblib\r\nimport os\r\nimport json\r\nimport hashlib\r\nimport zipfile\r\nimport io\r\nimport os\r\nfrom django.utils.text import slugify\r\nfrom urllib.parse import quote\r\n\r\n\r\nclass UploadFileView(APIView):\r\n\r\n    permission_classes = [IsAuthenticated]\r\n\r\n    def post(self, request):\r\n\r\n        request.data['user'] = request.user.id\r\n        serializer = UploadFileSerializer(data=request.data)\r\n\r\n        if serializer.is_valid():\r\n            # extension = serializer.validated_data['file_path'].split('.')[-1]\r\n            file_path = serializer.validated_data['file_path']\r\n            file_name = file_path.name\r\n            print(file_name)\r\n            serializer.save()\r\n\r\n            return Response(serializer.data, status=status.HTTP_200_OK)\r\n        \r\n        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)\r\n    \r\nclass DatasetPreviewAPI(APIView):\r\n    def post(self, request):\r\n        serializer = DatasetPreviewSerializer(data=request.data)\r\n        if not serializer.is_valid():\r\n            return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)\r\n\r\n        dataset_obj = request.FILES.get('dataset')\r\n        rows_count = int(request.data.get('row_count', 5))  # Default to 5 rows if not specified\r\n\r\n        if not dataset_obj:\r\n            return Response({\"error\": \"No file uploaded.\"}, status=status.HTTP_400_BAD_REQUEST)\r\n        \r\n        try:\r\n            if dataset_obj.name.endswith('.csv'):\r\n                df = pd.read_csv(dataset_obj)\r\n            elif dataset_obj.name.endswith(('.xls', '.xlsx')):\r\n                df = pd.read_excel(dataset_obj)\r\n            else:\r\n                return Response(\r\n                    {\"error\": \"Unsupported file format. Only CSV and Excel files are supported\"},\r\n                    status=status.HTTP_400_BAD_REQUEST\r\n                )\r\n\r\n            # Prepare response data in the format expected by frontend\r\n            if rows_count>df.shape[0]:\r\n                rows_count = df.shape[0]\r\n                \r\n            preview_data = df.head(rows_count).fillna('').to_dict(orient='records')\r\n            columns = list(df.columns)\r\n            try:\r\n                stats = df.describe()\r\n            except Exception as e:\r\n                stats = {\"error\": f\"Could not generate stats: {str(e)}\"}\r\n\r\n            try:\r\n                correlation = df.corr(numeric_only=True).fillna('').to_dict()\r\n            except Exception as e:\r\n                correlation = {\"error\": f\"Could not generate correlation: {str(e)}\"}\r\n            \r\n            # Simple type detection\r\n            column_types = {}\r\n            for col in columns:\r\n                if pd.api.types.is_numeric_dtype(df[col]):\r\n                    column_types[col] = 'numeric'\r\n                else:\r\n                    column_types[col] = 'categorical'\r\n\r\n            return Response({\r\n                \"data\": preview_data,\r\n                \"columns\": columns,\r\n                \"column_types\": column_types,\r\n                \"stats\":stats,\r\n                \"correlation\":correlation\r\n            }, status=status.HTTP_200_OK)\r\n\r\n        except Exception as e:\r\n            return Response(\r\n                {\"error\": f\"Error processing file: {str(e)}\"},\r\n                status=status.HTTP_500_INTERNAL_SERVER_ERROR\r\n            )\r\n            \r\n\r\nclass ColumnsView(APIView):\r\n\r\n    def post(self,request):\r\n        try:\r\n            # uploaded_file = UploadedDataset.objects.get(pk=pk)\r\n            # extension = os.path.splitext(uploaded_file.file_name)[1].lower()\r\n            # file_path = uploaded_file.file_path.path\r\n            dataset = request.FILES('dataset')\r\n            df = read_file(dataset)\r\n\r\n            columns = df.columns.tolist()  # Convert Index object to a list\r\n\r\n            return Response({'columns':columns}, status=status.HTTP_200_OK)\r\n\r\n        except UploadedDataset.DoesNotExist:\r\n            return Response({\"error\": \"File not found.\"}, status=status.HTTP_404_NOT_FOUND)\r\n        except pd.errors.EmptyDataError:\r\n            return Response({\"error\": \"The file is empty.\"}, status=status.HTTP_400_BAD_REQUEST)\r\n        except pd.errors.ParserError:\r\n            return Response({\"error\": \"The file is not a valid CSV or Excel file.\"}, status=status.HTTP_400_BAD_REQUEST)\r\n        except Exception as e:\r\n            return Response({\"error\": f\"Failed to process the file: {str(e)}\"}, status=status.HTTP_400_BAD_REQUEST)\r\n        \r\n\r\nclass ModelTrainigView(APIView):\r\n    permission_classes = [IsAuthenticated]\r\n\r\n    def post(self, request):\r\n        try:\r\n            # 1. Validate file exists\r\n            if 'dataset' not in request.FILES:\r\n                return Response({\"error\": \"No file uploaded\"}, status=400)\r\n\r\n            dataset = request.FILES['dataset']\r\n            name = request.data.get('name')\r\n\r\n            # 2. Validate config exists and is valid JSON\r\n            if 'config' not in request.data:\r\n                return Response({\"error\": \"No config provided\"}, status=400)\r\n\r\n            try:\r\n                config = json.loads(request.data.get('config'))\r\n            except json.JSONDecodeError as e:\r\n                return Response({\"error\": f\"Invalid JSON config: {str(e)}\"}, status=400)\r\n\r\n            # 3. Validate required config fields\r\n            required_fields = ['features', 'target_column', 'model_type']\r\n            missing_fields = [field for field in required_fields if field not in config]\r\n            if missing_fields:\r\n                return Response({\r\n                    \"error\": \"Missing required fields in config\",\r\n                    \"missing_fields\": missing_fields\r\n                }, status=400)\r\n\r\n            # 4. Compute hash and check if file already exists\r\n            dataset_hash = calculate_dataset_hash(dataset=dataset)\r\n\r\n            file_instance, created = UploadedDataset.objects.get_or_create(\r\n                dataset_hash=dataset_hash,\r\n                defaults={\r\n                    'dataset': dataset,\r\n                    'name': name,\r\n                    'user': request.user\r\n                }\r\n            )\r\n\r\n            # 5. Prepare data for config serializer\r\n            serializer_data = {\r\n                'dataset': file_instance.id,\r\n                'user': request.user.id,\r\n                **config\r\n            }\r\n\r\n            serializer = ModelConfigSerializer(data=serializer_data)\r\n            if not serializer.is_valid():\r\n                return Response({\r\n                    \"error\": \"Validation error\",\r\n                    \"details\": serializer.errors\r\n                }, status=400)\r\n\r\n            # 6. Read the dataset from stored file (always use DB version)\r\n            try:\r\n                df = pd.read_csv(file_instance.dataset)\r\n\r\n                if df.empty:\r\n                    return Response({\"error\": \"Uploaded file is empty\"}, status=400)\r\n\r\n                # Validate features and target\r\n                missing_features = [f for f in config['features'] if f not in df.columns]\r\n                if missing_features:\r\n                    return Response({\r\n                        \"error\": \"Some features not found in dataset\",\r\n                        \"missing_features\": missing_features\r\n                    }, status=400)\r\n\r\n                if config['target_column'] not in df.columns:\r\n                    return Response({\r\n                        \"error\": f\"Target column '{config['target_column']}' not found in dataset\"\r\n                    }, status=400)\r\n                \r\n                print(f\"Training with new parameters: {config.get('parameters')}\")\r\n\r\n                # 7. Train the model\r\n                feature_types, categorical_values, model, feature_encoder, scaler, target_encoder, accuracy = preprocess_and_train(df,config={\r\n                    'features': config['features'],\r\n                    'target': config['target_column'],\r\n                    'encoder': config['encoder'],\r\n                    'scaler': config['scaler'],\r\n                    'test_size': float(config['test_size']),\r\n                    'random_state': int(config['random_state']),\r\n                    'model_type': config['model_type'],\r\n                    'stratify': config.get('stratify', False),\r\n                    'problem_type': config.get('problem_type'),\r\n                    \"parameters\": clean_parameters(config.get(\"parameters\", {}))\r\n                })\r\n\r\n                config['feature_types'] = feature_types\r\n                config['categorical_values'] = categorical_values\r\n\r\n                # Debug log (optional)\r\n                print(\"Training model with config:\", config)\r\n                print(\"Accuracy:\", accuracy)\r\n\r\n                # 8. Cache trained components\r\n                model_cache_key = f'trained_model_{uuid.uuid4()}'\r\n                encoder_cache_key = f'trained_encoder_{uuid.uuid4()}'\r\n                scaler_cache_key = f'trained_scaler_{uuid.uuid4()}'\r\n                target_encoder_cache_key = f'target_encoder_{uuid.uuid4()}'\r\n\r\n                cache.set(model_cache_key, model, timeout=3600)\r\n                cache.set(encoder_cache_key, feature_encoder, timeout=3600)\r\n                cache.set(scaler_cache_key, scaler, timeout=3600)\r\n                cache.set(target_encoder_cache_key, target_encoder, timeout=3600)\r\n\r\n                # 9. Save config to DB\r\n                serializer.validated_data['accuracy'] = accuracy\r\n\r\n                # 10. Return response\r\n                return Response({\r\n                'name':name,\r\n                'dataset': file_instance.id,\r\n                'config': {\r\n                    'model_type': config['model_type'],\r\n                    'features': config['features'],\r\n                    'feature_types': config['feature_types'],\r\n                    'categorical_values': config['categorical_values'],\r\n                    'target_column': config['target_column'],\r\n                    'encoder': config['encoder'],\r\n                    'scaler': config['scaler'],\r\n                    'test_size': config['test_size'],\r\n                    'random_state': config['random_state'],\r\n                    'stratify': config.get('stratify', False),\r\n                    'parameters': config.get('parameters', {}),\r\n                    'problem_type': config.get('problem_type', ''),\r\n                    'accuracy': accuracy\r\n                },\r\n                \"file_status\": \"new\" if created else \"existing\",\r\n                'accuracy': accuracy,\r\n                'model_cache_key': model_cache_key,\r\n                'encoder_cache_key': encoder_cache_key,\r\n                'scaler_cache_key': scaler_cache_key,\r\n                'target_encoder_cache_key': target_encoder_cache_key\r\n                })\r\n\r\n            except Exception as e:\r\n                return Response({\"error\": f\"Model training failed: {str(e)}\"}, status=400)\r\n\r\n        except Exception as e:\r\n            return Response({\"error\": f\"Server error: {str(e)}\"}, status=500)\r\n        \r\nclass SaveModelView(APIView):\r\n\r\n    permission_classes = [IsAuthenticated]\r\n\r\n    def post(self, request):\r\n        # Validate required fields\r\n        required_fields = ['name','dataset', 'config','accuracy', 'model_cache_key','encoder_cache_key','scaler_cache_key', 'target_encoder_cache_key']\r\n        for field in required_fields:\r\n            if field not in request.data:\r\n                return Response(\r\n                    {'error': f'Missing required field: {field}'},\r\n                    status=status.HTTP_400_BAD_REQUEST\r\n                )\r\n\r\n        # Get cache keys with fallbacks\r\n        model_cache_key = request.data.get('model_cache_key')\r\n        encoder_cache_key = request.data.get('encoder_cache_key')\r\n        scaler_cache_key = request.data.get('scaler_cache_key')\r\n        target_encoder_cache_key = request.data.get('target_encoder_cache_key')\r\n\r\n        config = request.data.get('config')\r\n        dataset = request.data.get('dataset')\r\n        name = request.data.get('name')\r\n        accuracy = request.data.get('accuracy')\r\n\r\n        try:\r\n            config = request.data.get('config')\r\n            if isinstance(config, str):\r\n                config = json.loads(config)\r\n        except Exception as e:\r\n            return Response({'error': f'Invalid config format: {str(e)}'}, status=400)\r\n\r\n        # Retrieve objects from cache\r\n        try:\r\n            model = cache.get(model_cache_key)\r\n            if not model:\r\n                return Response(\r\n                    {'error': 'Model not found in cache. Please train the model first.'},\r\n                    status=status.HTTP_404_NOT_FOUND\r\n                )\r\n\r\n            encoder = cache.get(encoder_cache_key)\r\n            scaler = cache.get(scaler_cache_key)\r\n            target_encoder = cache.get(target_encoder_cache_key)\r\n\r\n        except Exception as e:\r\n            return Response(\r\n                {'error': f'Error retrieving from cache: {str(e)}'},\r\n                status=status.HTTP_500_INTERNAL_SERVER_ERROR\r\n            )\r\n\r\n        try:\r\n            model_file_name = f'{name}_{uuid.uuid4().hex[:8]}.joblib'\r\n            model_file_path = os.path.join(settings.MEDIA_ROOT, 'saved_models', model_file_name)\r\n            os.makedirs(os.path.dirname(model_file_path), exist_ok=True)\r\n            joblib.dump(model, model_file_path)\r\n            with open(model_file_path, 'rb') as f:\r\n                model_file_content = ContentFile(f.read(), name=model_file_name)\r\n        except Exception as e:\r\n            return Response(\r\n                {'error': f'Error saving model: {str(e)}'},\r\n                status=status.HTTP_500_INTERNAL_SERVER_ERROR\r\n            )\r\n\r\n        # Save encoder file if exists\r\n        encoder_file_content = None\r\n        if encoder:\r\n            try:\r\n                encoder_file_name = f'{name}_encoder_{uuid.uuid4().hex[:8]}.joblib'\r\n                encoder_file_path = os.path.join(settings.MEDIA_ROOT, 'saved_encoders', encoder_file_name)\r\n                os.makedirs(os.path.dirname(encoder_file_path), exist_ok=True)\r\n                joblib.dump(encoder, encoder_file_path)\r\n                with open(encoder_file_path, 'rb') as f:\r\n                    encoder_file_content = ContentFile(f.read(), name=encoder_file_name)\r\n            except Exception as e:\r\n                return Response(\r\n                    {'error': f'Error saving encoder: {str(e)}'},\r\n                    status=status.HTTP_500_INTERNAL_SERVER_ERROR\r\n                )\r\n\r\n        # Save scaler file if exists\r\n        scaler_file_content = None\r\n        if scaler:\r\n            try:\r\n                scaler_file_name = f'{name}_scaler_{uuid.uuid4().hex[:8]}.joblib'\r\n                scaler_file_path = os.path.join(settings.MEDIA_ROOT, 'saved_scalers', scaler_file_name)\r\n                os.makedirs(os.path.dirname(scaler_file_path), exist_ok=True)\r\n                joblib.dump(scaler, scaler_file_path)\r\n                with open(scaler_file_path, 'rb') as f:\r\n                    scaler_file_content = ContentFile(f.read(), name=scaler_file_name)\r\n            except Exception as e:\r\n                return Response(\r\n                    {'error': f'Error saving scaler: {str(e)}'},\r\n                    status=status.HTTP_500_INTERNAL_SERVER_ERROR\r\n                )\r\n            \r\n        # Save target encoder file if exists\r\n        target_encoder_content = None\r\n        if target_encoder:\r\n            try:\r\n                target_encoder_name = f'{name}_target_encoder_{uuid.uuid4().hex[:8]}.joblib'\r\n                target_encoder_path = os.path.join(settings.MEDIA_ROOT, 'saved_target_encoders', target_encoder_name)\r\n                os.makedirs(os.path.dirname(target_encoder_path), exist_ok=True)\r\n                joblib.dump(target_encoder, target_encoder_path)\r\n                with open(target_encoder_path, 'rb') as f:\r\n                    target_encoder_content= ContentFile(f.read(), name=target_encoder_name)\r\n            except Exception as e:\r\n                return Response(\r\n                    {'error': f'Error saving scaler: {str(e)}'},\r\n                    status=status.HTTP_500_INTERNAL_SERVER_ERROR\r\n                )\r\n            \r\n        accuracy_val = 0.0  # âœ… Initialize with default\r\n            # print('Config accuracy:',config.get('accuracy'))\r\n            # accuracy = config.get('accuracy')\r\n        print('Accuracy:',accuracy)\r\n        if config.get('problem_type') == 'regression':\r\n            # For regression models, use r2_score as the accuracy\r\n            r2_score = accuracy.get('r2_score') if accuracy else None\r\n            try:\r\n                accuracy_val = float(r2_score) if r2_score is not None else 0.0\r\n            except (TypeError, ValueError):\r\n                accuracy_val = 0.0\r\n        else:\r\n            # For classification models, use the normal accuracy\r\n            # accuracy = config.get('accuracy')\r\n            if isinstance(accuracy, dict):\r\n                accuracy_val = accuracy.get('accuracy_score', 0.0)\r\n            try:\r\n                accuracy_val = float(accuracy_val)\r\n            except (TypeError, ValueError):\r\n                return Response({\"error\": \"Invalid accuracy value\"}, status=400)\r\n        accuracy_val = round(accuracy_val*100,2)\r\n        print('Accuracy value',accuracy_val)\r\n        print(\"Received parameters:\", config.get(\"parameters\", {}))\r\n        print(\"Cleaned parameters:\", clean_parameters(config.get(\"parameters\", {})))\r\n\r\n            # feature_types = config.get('feature_types')\r\n            # print('Feature_types:',feature_types)\r\n\r\n            # categorical_values = config.get('categorical_values')\r\n            # print('Categorical_values')\r\n\r\n        # Save the config model now\r\n        try:\r\n            config_obj = ModelConfig.objects.create(\r\n                dataset_id=dataset,\r\n                user=request.user,\r\n                model_type=config.get('model_type'),\r\n                features=config.get('features'),\r\n                feature_types=config.get('feature_types'),\r\n                categorical_values=config.get('categorical_values'),\r\n                target_column=config.get('target_column'),\r\n                encoder=config.get('encoder'),\r\n                scaler=config.get('scaler'),\r\n                test_size=float(config.get('test_size')),\r\n                random_state=config.get('random_state'),\r\n                stratify=config.get('stratify'),\r\n                accuracy = accuracy_val,\r\n                parameters=config.get(\"parameters\", {}),\r\n                problem_type=config.get(\"problem_type\", \"\")\r\n            )\r\n        except Exception as e:\r\n            return Response({\"error\": f\"Failed to save model config: {str(e)}\"}, status=500)\r\n\r\n        # Prepare data for serializer\r\n        data = {\r\n            \"name\":name,\r\n            \"user\": request.user.id,\r\n            \"dataset\": dataset,\r\n            \"algorithm\": config_obj.model_type,\r\n            \"accuracy\": config_obj.accuracy,\r\n            \"config\": config_obj.id,\r\n            \"model_file\": model_file_content,\r\n            \"encoder_file\": encoder_file_content,\r\n            \"scaler_file\": scaler_file_content,\r\n            \"target_encoder\":target_encoder_content\r\n        }\r\n\r\n        # Validate and save\r\n        serializer = SaveModelSerializer(data=data)\r\n        if serializer.is_valid():\r\n            try:\r\n                serializer.save()\r\n                return Response(serializer.data, status=status.HTTP_201_CREATED)\r\n            except Exception as e:\r\n                return Response(\r\n                    {'error': f'Error saving to database: {str(e)}'},\r\n                    status=status.HTTP_500_INTERNAL_SERVER_ERROR\r\n                )\r\n        \r\n        return Response(serializer.errors, status=status.HTTP_400_BAD_REQUEST)\r\n    \r\n\r\n    def get(self, request):\r\n        try:\r\n            # Prefetch related data to optimize queries\r\n            models = SavedModel.objects.filter(\r\n                user=request.user, \r\n                is_active=True\r\n            ).select_related(\r\n                'dataset',\r\n                'config'\r\n            ).order_by('-created_at')\r\n            \r\n            serializer = SaveModelSerializer(models, many=True)\r\n            return Response(serializer.data, status=status.HTTP_200_OK)\r\n        except Exception as e:\r\n            return Response(\r\n                {'error': f'Error retrieving models: {str(e)}'},\r\n                status=status.HTTP_500_INTERNAL_SERVER_ERROR\r\n            )\r\n        \r\n\r\nclass SavedModelDetailView(APIView):\r\n    permission_classes = [IsAuthenticated]\r\n\r\n    def delete(self, request, pk):\r\n        try:\r\n            # Get model and verify ownership\r\n            model = SavedModel.objects.get(pk=pk, user=request.user)\r\n\r\n            config_id = model.config\r\n            if config_id:\r\n                config = ModelConfig.objects.get(pk=config_id)\r\n                config.delete()\r\n\r\n            # Delete associated files\r\n            if model.model_file:\r\n                model.model_file.delete()\r\n            if model.encoder_file:\r\n                model.encoder_file.delete()\r\n            if model.scaler_file:\r\n                model.scaler_file.delete()\r\n            if model.target_encoder:\r\n                model.target_encoder.delete()\r\n\r\n            # Delete the model record\r\n            model.delete()\r\n            \r\n            return Response(status=status.HTTP_204_NO_CONTENT)\r\n            \r\n        except SavedModel.DoesNotExist:\r\n            return Response(\r\n                {'error': 'Model not found or you don\\'t have permission'},\r\n                status=status.HTTP_404_NOT_FOUND\r\n            )\r\n        except Exception as e:\r\n            return Response(\r\n                {'error': str(e)},\r\n                status=status.HTTP_500_INTERNAL_SERVER_ERROR\r\n            )\r\n        \r\nclass ModelFeaturesView(APIView):\r\n    permission_classes = [IsAuthenticated]\r\n\r\n    def get(self, request, pk):\r\n        try:\r\n            # Get model and verify ownership\r\n            model = SavedModel.objects.get(pk=pk, user=request.user)\r\n            features = model.config.features\r\n\r\n            return Response({'features':features},status=status.HTTP_200_OK)\r\n            \r\n        except SavedModel.DoesNotExist:\r\n            return Response(\r\n                {'error': 'Model not found or you don\\'t have permission'},\r\n                status=status.HTTP_404_NOT_FOUND\r\n            )\r\n\r\n# views.py\r\nclass PredictionView(APIView):\r\n    permission_classes = [IsAuthenticated]\r\n\r\n    def post(self, request, pk):\r\n        try:\r\n            # Get model with config\r\n            saved_model = SavedModel.objects.select_related('config').get(pk=pk, user=request.user)\r\n            config = saved_model.config\r\n            \r\n            # Validate inputs\r\n            input_data = request.data.get('inputs', [])\r\n            columns = request.data.get('columns', config.features)\r\n            \r\n            if not input_data:\r\n                return Response(\r\n                    {\"error\": \"No input data provided\"},\r\n                    status=status.HTTP_400_BAD_REQUEST\r\n                )\r\n            \r\n            if len(input_data) != len(columns):\r\n                return Response(\r\n                    {\"error\": f\"Expected {len(columns)} features, got {len(input_data)}\"},\r\n                    status=status.HTTP_400_BAD_REQUEST\r\n                )\r\n\r\n            # Convert all inputs to float\r\n            try:\r\n                features = input_data\r\n            except ValueError as e:\r\n                return Response(\r\n                    {\"error\": f\"Invalid input value: {str(e)}\"},\r\n                    status=status.HTTP_400_BAD_REQUEST\r\n                )\r\n\r\n            # Get file paths\r\n            model_path = saved_model.model_file.path\r\n            encoder_path = saved_model.encoder_file.path if saved_model.encoder_file else None\r\n            scaler_path = saved_model.scaler_file.path if saved_model.scaler_file else None\r\n            target_encoder_path = saved_model.target_encoder.path if saved_model.target_encoder else None\r\n            \r\n            # Load preprocessing objects\r\n            scaler = joblib.load(scaler_path) if scaler_path and os.path.exists(scaler_path) else None\r\n            encoder = joblib.load(encoder_path) if encoder_path and os.path.exists(encoder_path) else None\r\n            target_encoder = joblib.load(target_encoder_path) if target_encoder_path and os.path.exists(target_encoder_path) else None\r\n\r\n            # Make prediction\r\n            predicted_output = load_model_and_predict(\r\n                model_path=model_path,\r\n                features=features,\r\n                columns=columns,\r\n                encoder=encoder,\r\n                scaler=scaler,\r\n                target_encoder=target_encoder\r\n            )\r\n            \r\n            return Response({'prediction': str(predicted_output[0])})\r\n            \r\n        except SavedModel.DoesNotExist:\r\n            return Response(\r\n                {\"error\": \"Model not found or access denied\"},\r\n                status=status.HTTP_404_NOT_FOUND\r\n            )\r\n        except Exception as e:\r\n            return Response(\r\n                {\"error\": f\"Prediction error: {str(e)}\"},\r\n                status=status.HTTP_500_INTERNAL_SERVER_ERROR\r\n            )\r\n        \r\nclass UserTrainedModelsView(APIView):\r\n\r\n    permission_classes = [IsAuthenticated]\r\n\r\n    def get(self, request):\r\n        saved_model = SavedModel.objects.filter(user=request.user)\r\n        serializer = SaveModelSerializer(saved_model, many=True)\r\n        if saved_model:\r\n            return Response(serializer.data, status=status.HTTP_200_OK)\r\n        return Response({'error':'No records found for user'}, status=status.HTTP_400_BAD_REQUEST)\r\n\r\n\r\nclass ModelDownloadView(APIView):\r\n    permission_classes = [IsAuthenticated]\r\n\r\n    def get(self, request, pk):\r\n        try:\r\n            saved_model = SavedModel.objects.get(pk=pk, user=request.user)\r\n            print(saved_model.model_file)\r\n            print(saved_model.encoder_file)\r\n            print(saved_model.scaler_file)\r\n            print(saved_model.target_encoder)\r\n            \r\n            # Create filename using model name (sanitized) and ID\r\n            from django.utils.text import slugify\r\n            filename = f\"{slugify(saved_model.name)}_{pk}.zip\"  # slugify handles special chars\r\n            \r\n            # Create in-memory zip\r\n            zip_buffer = io.BytesIO()\r\n            with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:\r\n                # Add model file\r\n                if saved_model.model_file and os.path.exists(saved_model.model_file.path):\r\n                    zip_file.write(saved_model.model_file.path, 'model.joblib')\r\n                if saved_model.encoder_file and os.path.exists(saved_model.encoder_file.path):\r\n                    zip_file.write(saved_model.encoder_file.path, 'encoder.joblib')\r\n                if saved_model.scaler_file and os.path.exists(saved_model.scaler_file.path):\r\n                    zip_file.write(saved_model.scaler_file.path, 'scaler.joblib')\r\n                if saved_model.target_encoder and os.path.exists(saved_model.target_encoder.path):\r\n                    zip_file.write(saved_model.target_encoder.path, 'target_encoder.joblib')\r\n            \r\n            zip_buffer.seek(0)\r\n            response = HttpResponse(zip_buffer, content_type='application/zip')\r\n            \r\n            # Set filename in header\r\n            from urllib.parse import quote\r\n            response['Content-Disposition'] = (\r\n                f\"attachment; \"\r\n                f\"filename*=UTF-8''{quote(filename)};\"\r\n                f'filename=\"{filename}\"'\r\n            )\r\n            return response\r\n            \r\n        except SavedModel.DoesNotExist:\r\n            return Response({\"error\": \"Model not found\"}, status=status.HTTP_404_NOT_FOUND)\r\n        except Exception as e:\r\n            return Response({\"error\": f\"Download failed: {str(e)}\"}, status=status.HTTP_500_INTERNAL_SERVER_ERROR)\r\n\r\n@api_view(['GET'])\r\ndef get_all_files(request):\r\n    files = UploadedDataset.objects.all()\r\n    serializer = UploadFileSerializer(files, many=True)\r\n\r\n    return Response(serializer.data, status=status.HTTP_200_OK)\r\n\r\n\r\n@api_view(['GET'])\r\ndef get_all_config(request):\r\n    configs = ModelConfig.objects.all()\r\n    serializer = ModelConfigSerializer(configs, many=True)\r\n\r\n    return Response(serializer.data, status=status.HTTP_200_OK)\r\n\r\n\r\n@api_view(['GET'])\r\ndef get_user_files(request,pk):\r\n    files = UploadedDataset.objects.filter(user=pk)\r\n    serializer = UploadFileSerializer(files, many=True)\r\n\r\n    return Response(serializer.data, status=status.HTTP_200_OK)\r\n\r\n\r\n\r\n@api_view(['GET'])\r\ndef get_user_config(request, pk):\r\n    configs = ModelConfig.objects.filter(user=pk)\r\n    serializer = ModelConfigSerializer(configs, many=True)\r\n\r\n    return Response(serializer.data, status=status.HTTP_200_OK)\r\n\r\n\r\n\r\n\r\n#===============Calculate Hash=====================\r\ndef calculate_dataset_hash(dataset):\r\n    hasher = hashlib.sha256()\r\n    for chunk in dataset.chunks():\r\n        hasher.update(chunk)\r\n    return hasher.hexdigest()\r\n\r\n\r\ndef clean_parameters(params):\r\n    cleaned = {}\r\n    for k, v in params.items():\r\n        if v in [None, \"\"]:\r\n            continue\r\n        try:\r\n            cleaned[k] = int(v) if str(v).isdigit() else float(v)\r\n        except ValueError:\r\n            cleaned[k] = v \r\n    return cleaned"
        }
    ]
}